System information Have I written custom code opposed using stock example script provided TensorFlow Yes script testing nccl reduce sum attached OS Platform Distribution e g Linux Ubuntu Linux Ubuntu TensorFlow installed source binary Binary TensorFlow version use command Python version Python CUDA cuDNN version GPU model memory v Gb Describe current behavior nccl reduce sum throws error feed devices fetch devices found graph nccl reduce works Describe expected behavior Expect get reduced tensor Code reproduce issue import tensorflow tf tensorflow python ops import nccl ops nccl tf device gpu tf constant dtype tf float tf device gpu b tf constant dtype tf float tf device gpu c nccl reduce sum b sess tf Session print sess run c Other info logs ubuntu ip ~ tensorpack examples ResNet $ python test nccl py I tensorflow core platform cpu feature guard cc Your CPU supports instructions TensorFlow binary compiled use AVX FMA I tensorflow stream executor cuda cuda gpu executor cc successful NUMA node read SysFS negative value must least one NUMA node returning NUMA node zero I tensorflow stream executor cuda cuda gpu executor cc successful NUMA node read SysFS negative value must least one NUMA node returning NUMA node zero I tensorflow stream executor cuda cuda gpu executor cc successful NUMA node read SysFS negative value must least one NUMA node returning NUMA node zero I tensorflow stream executor cuda cuda gpu executor cc successful NUMA node read SysFS negative value must least one NUMA node returning NUMA node zero I tensorflow compiler xla service service cc XLA service x c executing computations platform CUDA Devices I tensorflow compiler xla service service cc StreamExecutor device Tesla V SXM GB Compute Capability I tensorflow compiler xla service service cc StreamExecutor device Tesla V SXM GB Compute Capability I tensorflow compiler xla service service cc StreamExecutor device Tesla V SXM GB Compute Capability I tensorflow compiler xla service service cc StreamExecutor device Tesla V SXM GB Compute Capability I tensorflow core platform profile utils cpu utils cc CPU Frequency Hz I tensorflow compiler xla service service cc XLA service x bbd f executing computations platform Host Devices I tensorflow compiler xla service service cc StreamExecutor device undefined undefined I tensorflow core common runtime gpu gpu device cc Found device properties name Tesla V SXM GB major minor memoryClockRate GHz pciBusID b totalMemory GiB freeMemory GiB I tensorflow core common runtime gpu gpu device cc Found device properties name Tesla V SXM GB major minor memoryClockRate GHz pciBusID c totalMemory GiB freeMemory GiB I tensorflow core common runtime gpu gpu device cc Found device properties name Tesla V SXM GB major minor memoryClockRate GHz pciBusID totalMemory GiB freeMemory GiB I tensorflow core common runtime gpu gpu device cc Found device properties name Tesla V SXM GB major minor memoryClockRate GHz pciBusID e totalMemory GiB freeMemory GiB I tensorflow core common runtime gpu gpu device cc Adding visible gpu devices I tensorflow core common runtime gpu gpu device cc Device interconnect StreamExecutor strength edge matrix I tensorflow core common runtime gpu gpu device cc I tensorflow core common runtime gpu gpu device cc N Y Y Y I tensorflow core common runtime gpu gpu device cc Y N Y Y I tensorflow core common runtime gpu gpu device cc Y Y N Y I tensorflow core common runtime gpu gpu device cc Y Y Y N I tensorflow core common runtime gpu gpu device cc Created TensorFlow device job localhost replica task device GPU MB memory physical GPU device name Tesla V SXM GB pci bus id b compute capability I tensorflow core common runtime gpu gpu device cc Created TensorFlow device job localhost replica task device GPU MB memory physical GPU device name Tesla V SXM GB pci bus id c compute capability I tensorflow core common runtime gpu gpu device cc Created TensorFlow device job localhost replica task device GPU MB memory physical GPU device name Tesla V SXM GB pci bus id compute capability I tensorflow core common runtime gpu gpu device cc Created TensorFlow device job localhost replica task device GPU MB memory physical GPU device name Tesla V SXM GB pci bus id e compute capability Traceback recent call last File home ubuntu venv lib python site packages tensorflow python client session py line call return fn args File home ubuntu venv lib python site packages tensorflow python client session py line run fn options feed dict fetch list target list run metadata File home ubuntu venv lib python site packages tensorflow python client session py line call tf sessionrun run metadata tensorflow python framework errors impl InvalidArgumentError Tensor NcclReduce specified either feed devices fetch devices found Graph During handling exception another exception occurred Traceback recent call last File test nccl py line module print sess run c File home ubuntu venv lib python site packages tensorflow python client session py line run run metadata ptr File home ubuntu venv lib python site packages tensorflow python client session py line run feed dict tensor options run metadata File home ubuntu venv lib python site packages tensorflow python client session py line run run metadata File home ubuntu venv lib python site packages tensorflow python client session py line call raise type e node def op message tensorflow python framework errors impl InvalidArgumentError Tensor NcclReduce specified either feed devices fetch devices found Graph Check checkpoints available TF TRT quantization test Use constant input test tensors instead random tensors Otherwise test sometimes fails depending generated random values This PR tries fix The root cause shared iterator resource private kernel resource cannot released ~ IteratorHandleOp https github com tensorflow tensorflow blob master tensorflow core kernels data iterator ops cc L L ResourceMgr Clear https github com tensorflow tensorflow blob master tensorflow core framework resource mgr cc L L needs called free shared resources For case session close tries release shared resources calling ResourceMgr Clear generator dataset finish iteration yet needs delete python generator calling finalizing function https github com tensorflow tensorflow blob master tensorflow core kernels data generator dataset op cc L However running finalizing function done function https github com tensorflow tensorflow blob master tensorflow core kernels data captured function cc L triggers ResourceMgr CleanUp https github com tensorflow tensorflow blob master tensorflow core framework resource mgr cc L L causes deadlock ResourceMgr Clear Here Traceback frame x fff libsystem kernel dylib psynch cvwait frame x fff e libsystem pthread dylib pthread cond wait frame x fff libc dylib std condition variable wait std unique lock std mutex frame x c c b libtensorflow framework nsync nsync mu semaphore p nsync nsync semaphore frame x c libtensorflow framework nsync nsync mu lock slow nsync nsync mu nsync waiter unsigned int nsync lock type frame x c libtensorflow framework nsync nsync mu lock nsync nsync mu frame x bbe cf libtensorflow framework tensorflow ResourceMgr Cleanup std basic string char std char traits char std allocator char const frame x fc pywrap tensorflow internal std function func tensorflow data CapturedFunction RunInstantiated std vector tensorflow Tensor std allocator tensorflow Tensor const std vector tensorflow Tensor std allocator tensorflow Tensor $ std allocator tensorflow data CapturedFunction RunInstantiated std vector tensorflow Tensor std allocator tensorflow Tensor const std vector tensorflow Tensor std allocator tensorflow Tensor $ void std basic string char std char traits char std allocator char const operator std basic string char std char traits char std allocator char const frame x fc ca pywrap tensorflow internal tensorflow ScopedStepContainer ~ ScopedStepContainer frame x fc pywrap tensorflow internal tensorflow data CapturedFunction RunInstantiated std vector tensorflow Tensor std allocator tensorflow Tensor const std vector tensorflow Tensor std allocator tensorflow Tensor frame x eb pywrap tensorflow internal tensorflow data GeneratorDatasetOp Dataset Iterator ~ Iterator frame x eb e pywrap tensorflow internal tensorflow data GeneratorDatasetOp Dataset Iterator ~ Iterator frame x eaea pywrap tensorflow internal tensorflow data anonymous namespace FlatMapDatasetOp Dataset Iterator ~ Iterator frame x fff libc dylib std shared weak count release shared frame x ec pywrap tensorflow internal tensorflow data IteratorResource ~ IteratorResource frame x ec e pywrap tensorflow internal tensorflow data IteratorResource ~ IteratorResource frame x bbe fa libtensorflow framework tensorflow ResourceMgr Clear frame x f f pywrap tensorflow internal tensorflow DirectSession ~ DirectSession frame x f aae pywrap tensorflow internal tensorflow DirectSession ~ DirectSession frame x fff libc dylib std shared weak count release shared frame x ceb f pywrap tensorflow internal tensorflow SessionRef Close frame x f b pywrap tensorflow internal TF CloseSession cc jsimsa We may locate exact statement exception raiased 