This PR allows to add tensorflow dependency for Go API using rules_go and bazel.I am trying to fine-tune inceptionv3 model using slim tensorflow library. 
I tried to read source code (no proper documentation) and figured out few things and I am able to fine-tune it and save the checkpoint. However, I am unable to understand certain things while writing the code for it.   Here are the steps I followed 

 1. I created a tf.record for my training data which is fine, now I am reading the data using the below code. 
[
  ```
  import tensorflow as tf
    import tensorflow.contrib.slim.nets as nets
    import tensorflow.contrib.slim as slim
    import matplotlib.pyplot as plt
    import numpy as np
    
    # get the data and labels here
    
    data_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/train1.tfrecords'
    
    # Training setting
    num_epochs = 100
    initial_learning_rate = 0.0002
    learning_rate_decay_factor = 0.7
    num_epochs_before_decay = 5
    num_classes = 5980
    
    # load the checkpoint
    model_path = '/home/sfarkya/nvidia_challenge/datasets/detrac/inception_v3.ckpt'
    
    # log directory
    log_dir = '/home/sfarkya/nvidia_challenge/datasets/detrac/fine_tuned_model'
    
    with tf.Session() as sess:
        feature = {'train/image': tf.FixedLenFeature([], tf.string),
                   'train/label': tf.FixedLenFeature([], tf.int64)}
    
        # Create a list of filenames and pass it to a queue
        filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)
    
        # Define a reader and read the next record
        reader = tf.TFRecordReader()
        _, serialized_example = reader.read(filename_queue)
    
        # Decode the record read by the reader
        features = tf.parse_single_example(serialized_example, features=feature)
    
        # Convert the image data from string back to the numbers
        image = tf.decode_raw(features['train/image'], tf.float32)
    
        # Cast label data into int32
        label = tf.cast(features['train/label'], tf.int32)
    
        # Reshape image data into the original shape
        image = tf.reshape(image, [128, 128, 3])
    
        # Creates batches by randomly shuffling tensors
        images, labels = tf.train.shuffle_batch([image, label], batch_size=64, capacity=128, num_threads=2,
                                                min_after_dequeue=64)](url)
```

Now I am finetuning the model using slim and this is the code. 

      init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())
        sess.run(init_op)
    
        # Create a coordinator and run all QueueRunner objects
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord)
    
        # load model
    
        # load the inception model from the slim library - we are using inception v3
        #inputL = tf.placeholder(tf.float32, (64, 128, 128, 3))
    
        img, lbl = sess.run([images, labels])
        one_hot_labels = slim.one_hot_encoding(lbl, num_classes)
    
        with slim.arg_scope(slim.nets.inception.inception_v3_arg_scope()):
            logits, inceptionv3 = nets.inception.inception_v3(inputs=img, num_classes=5980, is_training=True,
                                                              dropout_keep_prob=.6)
    
        # Restore convolutional layers:
    
        variables_to_restore = slim.get_variables_to_restore(exclude=['InceptionV3/Logits', 'InceptionV3/AuxLogits'])
        init_fn = slim.assign_from_checkpoint_fn(model_path, variables_to_restore)
    
        # loss function
        loss = tf.losses.softmax_cross_entropy(onehot_labels=one_hot_labels, logits = logits)
        total_loss = tf.losses.get_total_loss()
    
        # train operation
        train_op = slim.learning.create_train_op(total_loss + loss, optimizer= tf.train.AdamOptimizer(learning_rate=1e-4))
    
        print('Im here')
        # Start training.
        slim.learning.train(train_op, log_dir, init_fn=init_fn, save_interval_secs=20, number_of_steps= 10)

Now I have few questions about the code, which I am quite unable to figure out. Once, the code reaches **slim.learning.train** I don't see anything printing however, it's training, I can see in the log. Now, 
1. How do I give the number of epochs to the code? Right now it's running step by step with each step has batch_size = 64.  
2. How do I make sure that in the code **tf.train.shuffle_batch** I am not repeating my images and I am training over the whole dataset? 
3. How can I print the loss values while it's training?
4. If I create a validation set then how can I switch betweem training the model and validation? 

Thanks for the help!  ### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.9.0-6-amd64 #1 SMP Debian 4.9.82-1+deb9u3 (2018-03-02) x86_64 GNU/Linux
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 1.7.0-rc1
- **Python version**: 2.7.13
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: Google Cloud TPU v2-8 running TF 1.7
- **Exact command to reproduce**: See below


### Describe the problem
Using a Keras LSTM layer, and processing on a Google Cloud TPU results in a ```ValueError``` if the lstm is not unrolled. The layer behaves as expected if the TPUEstimator is configured to use CPU, or if the lstm loop is unrolled on either the TPU or CPU. Error raised by the TPU failure case:
```ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/lstm/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/lstm/while/while_context').```

### Source code / logs
Test code minimal example keras_lstm_test.py:
```python
""" Test for Keras model LSTM on TPU.
    Based on https://github.com/tensorflow/tpu/blob/master/models/official/resnet/
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from absl import flags
import absl.logging as _logging  # pylint: disable=unused-import
import tensorflow as tf
import numpy as np

from tensorflow.contrib.tpu.python.tpu import tpu_config
from tensorflow.contrib.tpu.python.tpu import tpu_estimator
from tensorflow.contrib.tpu.python.tpu import tpu_optimizer

# Define flags for the system
FLAGS = flags.FLAGS
flags.DEFINE_bool(
    'use_tpu', True,
    help=('Use TPU to execute the model for training and evaluation. If'
          ' --use_tpu=false, will use whatever devices are available to'
          ' TensorFlow by default (e.g. CPU and GPU)'))
flags.DEFINE_string(
    'tpu_name', default=None,
    help='Name of the Cloud TPU for Cluster Resolvers.')
flags.DEFINE_string(
    'model_dir', default=None,
    help=('The directory where the model and training/evaluation summaries are'
          ' stored.'))
flags.DEFINE_bool(
    'unroll_lstm', default=False,
    help=('Unrolls the Keras LSTM if this is True.'))

def main(unused_argv):
    # Get the TPU GRPC URL if it is needed
    if FLAGS.use_tpu:
        tpu_cluster_resolver = (
            tf.contrib.cluster_resolver.TPUClusterResolver(
                FLAGS.tpu_name))
        tpu_grpc_url = tpu_cluster_resolver.get_master()
    else:
        tpu_grpc_url = None

    # Set the configuration for the TPU
    config = tpu_config.RunConfig(
        master=tpu_grpc_url,
        model_dir=FLAGS.model_dir)

    # Create the TPUEstimator
    test_estimator = tpu_estimator.TPUEstimator(
            use_tpu=FLAGS.use_tpu,
            model_fn=test_model_fn,
            config=config,
            train_batch_size=1024)

    # Train the estimator for 10 steps
    test_estimator.train(input_fn, max_steps=10)

def input_fn(params):
    # Generate a random dataset of the correct shape
    data = np.random.rand(1024, 10, 10).astype(np.float32)
    label = np.random.rand(1024,10).astype(np.float32)

    # Repeat and batch
    rand_dataset = tf.data.Dataset.from_tensor_slices((data, label)).repeat()
    rand_dataset = rand_dataset.apply(tf.contrib.data.batch_and_drop_remainder(params['batch_size']))

    # Make input_fn for the TPUEstimator train step
    rand_dataset_fn = rand_dataset.make_one_shot_iterator().get_next()
    return rand_dataset_fn

def test_model_fn(features, labels, mode, params):
    ###################################################################
    # The Keras LSTM layer that causes an error unless it is unrolled #
    ###################################################################
    predictions = tf.keras.layers.LSTM(10, unroll=FLAGS.unroll_lstm)(features)

    # Create ops for the TPUEstimatorSpec
    loss = tf.losses.mean_squared_error(labels=labels, predictions=predictions)
    optimizer = tf.train.GradientDescentOptimizer(0.001)
    if FLAGS.use_tpu:
        optimizer = tpu_optimizer.CrossShardOptimizer(optimizer)
    global_step = tf.train.get_global_step()
    train_op = optimizer.minimize(loss, global_step)

    # Return the TPUEstimatorSpec
    return tpu_estimator.TPUEstimatorSpec(
        mode=mode,
        loss=loss,
        train_op=train_op)

if __name__ == '__main__':
    # Do the thing
    print('main wrapper')
    tf.logging.set_verbosity(tf.logging.INFO)
    tf.app.run()
```


Error on TPU with unroll_loop set to False, and sanitized log file:
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --tpu_name=tpu-name --unroll_lstm=False
WARNING: Logging before flag parsing goes to stderr.
W0329 19:54:49.412791 140278551017216 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:54:49.621851 140278551017216 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py", line 41, in autodetect
    from . import file_cache
  File "/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py", line 41, in <module>
    'file_cache is unavailable when using oauth2client >= 4.0.0')
ImportError: file_cache is unavailable when using oauth2client >= 4.0.0
2018-03-29 19:54:49.659244: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-29 19:54:49.662161: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:45589}
2018-03-29 19:54:49.663623: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:45589
W0329 19:54:49.753117 140278551017216 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f94eca3f7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:54:49.753689 140278551017216 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f94eca3d710>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:54:49.827284 140278551017216 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.
2018-03-29 19:54:49.828047: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
I0329 19:54:49.831892 140278551017216 tf_logging.py:116] Found TPU system:
I0329 19:54:49.832133 140278551017216 tf_logging.py:116] *** Num TPU Cores: 8
I0329 19:54:49.832345 140278551017216 tf_logging.py:116] *** Num TPU Workers: 1
I0329 19:54:49.832411 140278551017216 tf_logging.py:116] *** Num TPU Cores Per Worker: 8
I0329 19:54:49.832514 140278551017216 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]
I0329 19:54:49.845520 140278551017216 tf_logging.py:116] Calling model_fn.
Traceback (most recent call last):
  File "keras_lstm_test.py", line 99, in <module>
    tf.app.run()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py", line 126, in run
    _sys.exit(main(argv))
  File "keras_lstm_test.py", line 60, in main
    test_estimator.train(input_fn, max_steps=10)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 355, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 824, in _train_model
    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py", line 805, in _call_model_fn
    model_fn_results = self._model_fn(features=features, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py", line 1827, in _model_fn
    _train_on_tpu_system(ctx, model_fn_wrapper, dequeue_fn))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py", line 2016, in _train_on_tpu_system
    device_assignment=ctx.device_assignment)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py", line 491, in shard
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py", line 323, in replicate
    outputs = computation(*computation_inputs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py", line 2009, in multi_tpu_train_steps_on_single_shard
    name=b'loop')
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py", line 207, in repeat
    cond, body_wrapper, inputs=inputs, infeed_queue=infeed_queue, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py", line 169, in while_loop
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 3202, in while_loop
    result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2940, in BuildLoop
    pred, body, original_loop_vars, loop_vars, shape_invariants)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2877, in _BuildLoop
    body_result = body(*packed_vars_for_body)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py", line 120, in body_wrapper
    outputs = body(*(inputs + dequeue_ops))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/training_loop.py", line 203, in body_wrapper
    return [i + 1] + _convert_to_list(body(*args))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py", line 1076, in train_step
    self._call_model_fn(features, labels))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_estimator.py", line 1230, in _call_model_fn
    estimator_spec = self._model_fn(features=features, **kwargs)
  File "keras_lstm_test.py", line 87, in test_model_fn
    train_op = optimizer.minimize(loss, global_step)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 399, in minimize
    grad_loss=grad_loss)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu_optimizer.py", line 85, in compute_gradients
    return self._opt.compute_gradients(loss, var_list=var_list, **kwargs)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py", line 492, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 488, in gradients
    gate_gradients, aggregation_method, stop_gradients)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 625, in _GradientsHelper
    lambda: grad_fn(op, *out_grads))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 379, in _MaybeCompile
    return grad_fn()  # Exit early
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py", line 625, in <lambda>
    lambda: grad_fn(op, *out_grads))
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_grad.py", line 131, in _TensorArrayWriteGrad
    grad = g.read(index)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py", line 861, in read
    return self._implementation.read(index, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py", line 260, in read
    name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_data_flow_ops.py", line 6419, in tensor_array_read_v3
    dtype=dtype, name=name)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py", line 787, in _apply_op_helper
    op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 3290, in create_op
    op_def=op_def)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1696, in __init__
    self._control_flow_post_processing()
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py", line 1707, in _control_flow_post_processing
    self._control_flow_context.AddOp(self)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2429, in AddOp
    self._AddOpInternal(op)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2450, in _AddOpInternal
    real_x = self.AddValue(x)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 2382, in AddValue
    real_val = grad_ctxt.grad_state.GetRealValue(val)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 1152, in GetRealValue
    history_value = cur_grad_state.AddForwardAccumulator(cur_value)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 1017, in AddForwardAccumulator
    value, self.forward_context)
  File "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py", line 752, in GetMaxSizeFromNestedMaximumIterations
    "the tf.while_loop call ('%s')." % (value_name, while_ctxt.name))
ValueError: Cannot create a gradient accumulator for tensor 'TPUReplicate/loop/lstm/while/Identity:0' inside XLA while_loop because maximum_iterations was not passed to the tf.while_loop call ('TPUReplicate/loop/lstm/while/while_context').
```


Working as expected on TPU with unroll_lstm set to True:
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --tpu_name=tpu-name --unroll_lstm=True
WARNING: Logging before flag parsing goes to stderr.
W0329 19:54:56.462137 140718335936256 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:54:56.665755 140718335936256 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0
Traceback (most recent call last):
  File "/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/__init__.py", line 41, in autodetect
    from . import file_cache
  File "/usr/local/lib/python2.7/dist-packages/googleapiclient/discovery_cache/file_cache.py", line 41, in <module>
    'file_cache is unavailable when using oauth2client >= 4.0.0')
ImportError: file_cache is unavailable when using oauth2client >= 4.0.0
2018-03-29 19:54:56.704991: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2018-03-29 19:54:56.707871: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job local -> {0 -> localhost:42697}
2018-03-29 19:54:56.709444: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:333] Started server with target: grpc://localhost:42697
W0329 19:54:56.802102 140718335936256 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7ffb51dff7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:54:56.802637 140718335936256 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ffb51dfdcd0>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': u'grpc://10.240.1.2:8470', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': u'grpc://10.240.1.2:8470', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:54:56.876996 140718335936256 tf_logging.py:116] Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.
2018-03-29 19:54:56.877690: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:351] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
I0329 19:54:56.881433 140718335936256 tf_logging.py:116] Found TPU system:
I0329 19:54:56.881619 140718335936256 tf_logging.py:116] *** Num TPU Cores: 8
I0329 19:54:56.881828 140718335936256 tf_logging.py:116] *** Num TPU Workers: 1
I0329 19:54:56.881892 140718335936256 tf_logging.py:116] *** Num TPU Cores Per Worker: 8
I0329 19:54:56.881998 140718335936256 tf_logging.py:116] *** Available Devices: [_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_GPU:0, XLA_GPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184), _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184)]
I0329 19:54:56.894473 140718335936256 tf_logging.py:116] Calling model_fn.
I0329 19:55:00.045663 140718335936256 tf_logging.py:116] Done calling model_fn.
I0329 19:55:00.046016 140718335936256 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:55:01.532725 140718335936256 tf_logging.py:116] TPU job name tpu_worker
I0329 19:55:01.588900 140718335936256 tf_logging.py:116] Graph was finalized.
I0329 19:55:02.225465 140718335936256 tf_logging.py:116] Running local_init_op.
I0329 19:55:02.271645 140718335936256 tf_logging.py:116] Done running local_init_op.
I0329 19:55:02.415777 140718335936256 tf_logging.py:116] Init TPU system
I0329 19:55:07.818669 140718335936256 tf_logging.py:116] Start infeed thread controller
I0329 19:55:07.819324 140713782138624 tf_logging.py:116] Starting infeed thread controller.
I0329 19:55:07.819504 140718335936256 tf_logging.py:116] Start outfeed thread controller
I0329 19:55:07.820395 140713773745920 tf_logging.py:116] Starting outfeed thread controller.
I0329 19:55:10.587852 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:10.588713 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:12.060930 140718335936256 tf_logging.py:116] Saving checkpoints for 2 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:55:15.523288 140718335936256 tf_logging.py:116] loss = 0.4525105, step = 0
I0329 19:55:15.525207 140718335936256 tf_logging.py:116] loss = 0.4525105, step = 0
I0329 19:55:15.527029 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.527189 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.618277 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.618545 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.628783 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.629064 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.640600 140718335936256 tf_logging.py:116] Enqueue next (2) batch(es) of data to infeed.
I0329 19:55:15.640825 140718335936256 tf_logging.py:116] Dequeue next (2) batch(es) of data from outfeed.
I0329 19:55:15.649879 140718335936256 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:55:19.049213 140718335936256 tf_logging.py:116] Stop infeed thread controller
I0329 19:55:19.049483 140718335936256 tf_logging.py:116] Shutting down InfeedController thread.
I0329 19:55:19.049849 140713782138624 tf_logging.py:116] InfeedController received shutdown signal, stopping.
I0329 19:55:19.050069 140713782138624 tf_logging.py:116] Infeed thread finished, shutting down.
I0329 19:55:19.050215 140718335936256 tf_logging.py:116] Stop output thread controller
I0329 19:55:19.050323 140718335936256 tf_logging.py:116] Shutting down OutfeedController thread.
I0329 19:55:19.050463 140713773745920 tf_logging.py:116] OutfeedController received shutdown signal, stopping.
I0329 19:55:19.050602 140713773745920 tf_logging.py:116] Outfeed thread finished, shutting down.
I0329 19:55:19.050734 140718335936256 tf_logging.py:116] Shutdown TPU system.
I0329 19:55:19.303575 140718335936256 tf_logging.py:116] Loss for final step: 0.45125633.
```


Working as expected with unroll_loop set to either True or False on CPU:
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --use_tpu=False --unroll_lstm=False
WARNING: Logging before flag parsing goes to stderr.
W0329 19:55:58.036350 139650416416512 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:55:58.224196 139650416416512 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7f02ace3f7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:55:58.224781 139650416416512 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f02ace3d590>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:55:58.333888 139650416416512 tf_logging.py:116] Calling model_fn.
I0329 19:55:58.334151 139650416416512 tf_logging.py:116] Running train on CPU
I0329 19:55:58.917757 139650416416512 tf_logging.py:116] Done calling model_fn.
I0329 19:55:58.919229 139650416416512 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:56:00.058123 139650416416512 tf_logging.py:116] Graph was finalized.
2018-03-29 19:56:00.058509: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I0329 19:56:00.216192 139650416416512 tf_logging.py:116] Running local_init_op.
I0329 19:56:00.223177 139650416416512 tf_logging.py:116] Done running local_init_op.
I0329 19:56:01.895720 139650416416512 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:04.683254 139650416416512 tf_logging.py:116] loss = 0.4141244, step = 0
I0329 19:56:05.080931 139650416416512 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:08.176239 139650416416512 tf_logging.py:116] Loss for final step: 0.41163954.
```
```
$ python keras_lstm_test.py --model_dir=gs://my_bucket/keras_lstm_test --use_tpu=False --unroll_lstm=True
WARNING: Logging before flag parsing goes to stderr.
W0329 19:56:34.716190 140417782937344 tf_logging.py:126] From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.
Instructions for updating:
Use the retry module or similar alternatives.
main wrapper
W0329 19:56:34.914796 140417782937344 tf_logging.py:126] Estimator's model_fn (<function test_model_fn at 0x7fb55784e7d0>) includes params argument, but params are not passed to Estimator.
I0329 19:56:34.915416 140417782937344 tf_logging.py:116] Using config: {'_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=None, computation_shape=None, per_host_input_for_training=True, tpu_job_name=None, initial_infeed_sleep_secs=None), '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb55784c590>, '_cluster': None, '_model_dir': 'gs://my_bucket/keras_lstm_test', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_service': None, '_save_summary_steps': 100, '_num_ps_replicas': 0}
I0329 19:56:35.047240 140417782937344 tf_logging.py:116] Calling model_fn.
I0329 19:56:35.047514 140417782937344 tf_logging.py:116] Running train on CPU
I0329 19:56:37.489144 140417782937344 tf_logging.py:116] Done calling model_fn.
I0329 19:56:37.490300 140417782937344 tf_logging.py:116] Create CheckpointSaverHook.
I0329 19:56:39.153974 140417782937344 tf_logging.py:116] Graph was finalized.
2018-03-29 19:56:39.154479: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
I0329 19:56:39.485604 140417782937344 tf_logging.py:116] Running local_init_op.
I0329 19:56:39.513873 140417782937344 tf_logging.py:116] Done running local_init_op.
I0329 19:56:43.631685 140417782937344 tf_logging.py:116] Saving checkpoints for 1 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:47.166574 140417782937344 tf_logging.py:116] loss = 0.41451082, step = 0
I0329 19:56:48.535309 140417782937344 tf_logging.py:116] Saving checkpoints for 10 into gs://my_bucket/keras_lstm_test/model.ckpt.
I0329 19:56:52.381931 140417782937344 tf_logging.py:116] Loss for final step: 0.41207257.
```
